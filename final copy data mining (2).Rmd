---
title: "R Notebook - Getting started with Assignment 2 on the Lending Club case"
author: "sid b"
date: "IDs 572 Fall'24"
output:
  html_document:

---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 


Note: the following sections have R code for Assignment-2 of the Lending Club case.
This is example code - you need to modify/adapt this as needed for your analyses.
Please make sure you understand what the code does, and not blindly run through it. 



```{r results='hide'}
rm(list = ls())
library(tidyverse)
library(lubridate)
```


The lcDataSample.csv file contains a sample of data on 3-year loans which we will use for this analyses
```{r results='hide'}
setwd("/Users/krutikakulkarni/Documents/Data Mining/Assgn2")
list.files()
lcdf <- read_csv("lcDataSample.csv")
#look at the variables 
glimpse(lcdf)

#get summary stats of the variables
summary(lcdf)
```



#Explore the data
```{r}
# 2.a.1) Count the number of fully paid and charged off loans
lcdf %>% group_by(loan_status) %>% tally()

# Calculate the proportion of Charged Off vs Fully Paid loans
loan_status_proportion <- lcdf %>%
  filter(loan_status %in% c("Fully Paid", "Charged Off")) %>%
  group_by(loan_status) %>%
  summarise(count = n()) %>%
  mutate(proportion = count / sum(count))
print(loan_status_proportion)

# Remove values for loan_status other than 'Fully Paid' and 'Charged Off'
lcdf <- lcdf %>% filter(loan_status %in% c("Fully Paid", "Charged Off"))

# How does loan status vary by loan grade?
lcdf %>% group_by(loan_status, grade) %>% tally()
table(lcdf$loan_status, lcdf$grade)

# 2.a.ii) How does number of loans, loan amount, and interest rate vary by grade?
lcdf %>% group_by(grade) %>% summarise(total_loans = n())
lcdf %>% group_by(grade) %>% summarise(total_loan_amt = sum(loan_amnt))
lcdf %>% group_by(loan_status) %>% summarise(total_loan_amt = sum(loan_amnt))
lcdf %>% group_by(grade) %>% summarise(mean_loan_amt = mean(loan_amnt))
lcdf %>% group_by(grade, loan_status) %>% summarise(total_loan_amt = sum(loan_amnt))
lcdf %>% group_by(grade) %>% summarise(mean_int_rate = mean(as.numeric(gsub("%", "", int_rate))))

# Plot histograms and boxplots
ggplot(lcdf, aes(x = int_rate)) + geom_histogram()
ggplot(lcdf, aes(x = loan_amnt, fill = grade)) + geom_histogram()
ggplot(lcdf, aes(x = loan_amnt)) + geom_histogram() + facet_wrap(~loan_status)

# Loan amount by grade (boxplot)
ggplot(lcdf, aes(x = loan_amnt)) + geom_boxplot(aes(fill = grade))

# How does loan amount vary by loan status and grade?
ggplot(lcdf, aes(x = grade, y = loan_amnt, fill = loan_status)) + geom_boxplot()

# Filter larger loans (>= $20K) and plot loan status variation by grade
lcdf %>% filter(loan_amnt >= 20000) %>% 
  ggplot(aes(x = grade, y = loan_amnt, fill = loan_status)) + geom_boxplot()

# 2.a.iii) Interest rate summaries by grade and sub-grade
interest_rate_summary <- lcdf %>%
  group_by(grade, sub_grade) %>%
  summarise(
    avg_int_rate = mean(as.numeric(gsub("%", "", int_rate)), na.rm = TRUE),
    sd_int_rate = sd(as.numeric(gsub("%", "", int_rate)), na.rm = TRUE),
    min_int_rate = min(as.numeric(gsub("%", "", int_rate)), na.rm = TRUE),
    max_int_rate = max(as.numeric(gsub("%", "", int_rate)), na.rm = TRUE)
  ) %>%
  arrange(grade, sub_grade)

# Print the summary statistics for interest rates
print(interest_rate_summary)

# Boxplots for interest rates by grade and loan status
ggplot(lcdf, aes(x = int_rate, fill = grade)) + geom_boxplot()
ggplot(lcdf, aes(x = int_rate, fill = loan_status)) + geom_boxplot()
ggplot(lcdf, aes(x = grade, y = int_rate, fill = loan_status)) + geom_boxplot()

# Boxplots for interest rates by sub-grade
ggplot(lcdf, aes(x = int_rate, fill = sub_grade)) + geom_boxplot()

# Default rate and average interest rate by grade
lcdf %>% group_by(grade) %>%
  summarise(
    nLoans = n(), 
    defaults = sum(loan_status == "Charged Off"), 
    defaultRate = defaults / nLoans, 
    avgInterest = mean(as.numeric(gsub("%", "", int_rate)), na.rm = TRUE), 
    stdInterest = sd(as.numeric(gsub("%", "", int_rate)), na.rm = TRUE), 
    avgLoanAmt = mean(loan_amnt), 
    avgPmnt = mean(total_pymnt)
  )




```


Outliers - some examples on how we can examine if there are outliers based on specific variables
Are there any outliers? And should we try to remove these ?
```{r}

# 1. Data Summary for Numeric Variables
summary(lcdf)
lcdf %>% select_if(is.numeric) %>% summary()   # Summary for only numeric variables

# 2. Boxplots for Identifying Outliers
ggplot(lcdf, aes(x = loan_amnt)) + geom_boxplot(aes(fill = grade))
# Checking for extreme outliers in loan_amnt

ggplot(lcdf, aes(x = annual_inc)) + geom_boxplot()
# Boxplot for annual income

ggplot(lcdf, aes(x = loan_amnt)) + geom_boxplot(aes(fill = loan_status))
# Loan amount boxplot based on loan status

# 3. Summary of annual_inc (Checking for high incomes)
summary(lcdf$annual_inc)

# 4. Summary of joint income
summary(lcdf$annual_inc_joint)

# 5. Identify High-Income Outliers (annual income > $1.5M)
lcdf %>% filter(annual_inc > 1500000) %>% count()

# 6. Boxplot to Check High-Income Cases by Loan Status
ggplot(lcdf, aes(x = annual_inc)) + geom_boxplot(aes(fill = loan_status))

# 7. Removing High-Income Outliers
# Filter to keep rows where annual_inc is <= 1.5M
lcdf<- lcdf %>% filter(annual_inc <= 1500000)

# 8. Checking 'revol_util' Variable
summary(lcdf$revol_util)
boxplot(lcdf$revol_util)

# 9. Identify Outliers in 'revol_util'
out_ru <- boxplot(lcdf$revol_util, plot = FALSE)$out
out_ru_i <- which(lcdf$revol_util %in% out_ru)

# Show the outliers in 'revol_util'
lcdf[out_ru_i, ] %>% view()

# 10. Remove Outliers from 'revol_util'
lcdf<- lcdf[-out_ru_i, ]

# 11. Verify the Summary After Removing Outliers
summary(lcdf)

# 12. Visualize Boxplot of Loan Amount After Outlier Removal
ggplot(lcdf, aes(x = loan_amnt)) + geom_boxplot(aes(fill = grade))

# 13. Visualize Boxplot of Annual Income After Outlier Removal
ggplot(lcdf, aes(x = annual_inc)) + geom_boxplot()

# 14. Boxplot for revol_util After Outlier Removal
boxplot(lcdf$revol_util)

# 15. Optional: Exporting the filtered dataset to CSV
write.csv(lcdf, "filtered_loan_data.csv")



```



Total payments and recoveries
Can we assume that recoveries are only for Charged_off loans?
For charged-off loans, does total_pymnt include recoveries?
```{r}

#2.a".iv)

####This has only 94 observation which can be baised so not considering 
# Ensure dates are properly formatted
# Parse the issue and last payment dates properly
#lcdf$last_pymnt_d <- paste(lcdf$last_pymnt_d, "-01", sep = "")
#lcdf$last_pymnt_d <- parse_date_time(lcdf$last_pymnt_d, "ymd")

# Ensure issue_d is in the correct format as well
#lcdf$issue_d <- parse_date_time(lcdf$issue_d, "ymd")

# Filter fully paid loans and calculate the actual term
#actualTerm <- lcdf %>%
 # filter(loan_status == "Fully Paid") %>%
  #mutate(actualTerm = as.numeric(difftime(last_pymnt_d, issue_d, units = "days")) / 365) %>%
  #filter(!is.na(actualTerm))  # Remove rows with NA values in actualTerm

# View the result
#head(actualTerm)

#Summarising 
 #actualTerm%>% group_by(loan_status, actualTerm, grade) %>% tally()
#actualTerm %>% group_by(grade, actualTerm) %>% tally()
#actualTerm %>% group_by(grade) %>% summarise(mean(actualTerm), min(actualTerm), max(actualTerm))
#actualTerm %>% group_by(loan_status) %>% summarise(mean(actualTerm), min(actualTerm), max(actualTerm))

#boxplot(actualTerm$actualTerm ~ actualTerm$grade, xlab = "Loan Grades", 
#        ylab = "Actual Term (Years)", 
#        col = rainbow(length(unique(actualTerm$grade))),
#        main = "Box Plot of Actual Term by Loan Grade")
# Writing the table of loan_status and actualTerm to a CSV file
#write.csv(table(actualTerm$loan_status, actualTerm$actualTerm), 'term.csv')

# Displaying the table of loan_status and actualTerm in the console
#table(actualTerm$loan_status, actualTerm$actualTerm)""
#####
lcdf$last_pymnt_d<-paste(lcdf$last_pymnt_d, "-01", sep = "")
lcdf$last_pymnt_d<-parse_date_time(lcdf$last_pymnt_d,  "myd")

lcdf$actualTerm <- ifelse(lcdf$loan_status=="Fully Paid", as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)/dyears(1),3)

#Summarising for better understanding
lcdf %>% group_by(loan_status, actualTerm, grade) %>% tally()
lcdf %>% group_by(grade, actualTerm) %>% tally()
lcdf %>% group_by(grade) %>% summarise(mean(actualTerm), min(actualTerm), max(actualTerm))
lcdf %>% group_by(loan_status) %>% summarise(mean(actualTerm), min(actualTerm), max(actualTerm))

#plot
ggplot(lcdf, aes( x = actualTerm)) + geom_histogram(aes(fill=grade))
boxplot(lcdf$actualTerm ~ lcdf$grade, xlab = "Loan grades", ylab = "Actual term", col = colors(distinct = TRUE)) #geom_histogram(aes(fill=lcdf$grade, colours(distinct = TRUE)))

write.csv(table(lcdf$loan_status, lcdf$actualTerm), 'term')
#or, using table
table(lcdf$loan_status, lcdf$actualTerm)

#Then, considering this actual term, the actual annual return is
lcdf$actualReturn <- ifelse(lcdf$actualTerm>0, ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(1/lcdf$actualTerm)*100, 0)
#lcdf$actualReturn
lcdf %>% group_by(loan_status) %>% summarise(mean(actualReturn), mean(int_rate))
lcdf %>% group_by(grade) %>% summarise(mean(actualReturn), mean(int_rate))


lcdf %>% group_by(loan_status) %>%summarise(avgRec=mean(recoveries))
   #shows that recoveries are there only for the Charged-Off loans


#There are different variables for recoveries -- what is the total amount of recoveries?
lcdf %>% group_by(loan_status) %>% summarise(avgRec=mean(recoveries), avgPmnt=mean(total_pymnt), mean(total_rec_prncp), mean(total_rec_int), mean(total_rec_late_fee))
   #so we find that 'recoveries' has the total of recoveries on principal, on interest, and late-fees









```




Examine actual returns from a loan, and relation with int_rate
(for example, can one expect a 5%/year return from a loan with 5% int_rate?)
```{r}
#2.a.v)

# Calculate the annual percentage return
lcdf$annRet <- ((lcdf$total_pymnt - lcdf$funded_amnt) / lcdf$funded_amnt) * (12 / 36) * 100

# Group by grade and summarize defaults, interest rates, loan amounts, and payments
grade_summary <- lcdf %>%
  group_by(grade) %>%
  summarise(
    nLoans = n(),
    defaults = sum(loan_status == "Charged Off"),
    defaultrate = defaults / nLoans,
    avgInterest = mean(int_rate, na.rm = TRUE),
    stdInterest = sd(int_rate, na.rm = TRUE),
    avgLoanAmt = mean(loan_amnt, na.rm = TRUE),
    avgPmnt = mean(total_pymnt, na.rm = TRUE),
    avgRet = mean(annRet, na.rm = TRUE),
    stdRet = sd(annRet, na.rm = TRUE),
    minRet = min(annRet, na.rm = TRUE),
    maxRet = max(annRet, na.rm = TRUE)
  )

print(grade_summary)

# Group by sub-grade and summarize defaults, interest rates, loan amounts, and payments
subgrade_summary <- lcdf %>%
  group_by(sub_grade) %>%
  summarise(
    nLoans = n(),
    defaults = sum(loan_status == "Charged Off"),
    defaultrate = defaults / nLoans,
    avgInterest = mean(int_rate, na.rm = TRUE),
    stdInterest = sd(int_rate, na.rm = TRUE),
    avgLoanAmt = mean(loan_amnt, na.rm = TRUE),
    avgPmnt = mean(total_pymnt, na.rm = TRUE),
    avgRet = mean(annRet, na.rm = TRUE),
    stdRet = sd(annRet, na.rm = TRUE),
    minRet = min(annRet, na.rm = TRUE),
    maxRet = max(annRet, na.rm = TRUE)
  )

print(subgrade_summary)

# Investigate negative returns
negative_returns <- lcdf %>%
  select(loan_status, int_rate, funded_amnt, total_pymnt, annRet) %>%
  filter(annRet < 0)

# Count the number of negative returns by loan status
negative_returns_count <- lcdf %>%
  select(loan_status, int_rate, funded_amnt, total_pymnt, annRet) %>%
  filter(annRet < 0) %>%
  count(loan_status)

# Summary of returns from fully paid loans by grade
fully_paid_summary <- lcdf %>%
  filter(loan_status == "Fully Paid") %>%
  group_by(grade) %>%
  summarise(
    nLoans = n(),
    avgInterest = mean(int_rate, na.rm = TRUE),
    avgLoanAmt = mean(loan_amnt, na.rm = TRUE),
    avgPmnt = mean(total_pymnt, na.rm = TRUE),
    avgRet = mean(annRet, na.rm = TRUE),
    minRet = min(annRet, na.rm = TRUE),
    maxRet = max(annRet, na.rm = TRUE)
  )
print(fully_paid_summary)

# Summary of returns from charged off loans by grade
charged_off_summary <- lcdf %>%
  filter(loan_status == "Charged Off") %>%
  group_by(grade) %>%
  summarise(
    nLoans = n(),
    avgInterest = mean(int_rate, na.rm = TRUE),
    avgLoanAmt = mean(loan_amnt, na.rm = TRUE),
    avgPmnt = mean(total_pymnt, na.rm = TRUE),
    avgRet = mean(annRet, na.rm = TRUE),
    minRet = min(annRet, na.rm = TRUE),
    maxRet = max(annRet, na.rm = TRUE)
  )
print(charged_off_summary )

# Plot  Grade
ggplot(grade_summary, aes(x = grade, y = avgRet, fill = grade)) +
  geom_bar(stat = "identity") +
  labs(title = "Avg return by Grade", x = "Grade", y = "Avg Rt Rate") +
  theme_minimal()


# Plot  Sub-Grade
ggplot(subgrade_summary, aes(x = sub_grade, y = avgRet, fill = sub_grade)) +
  geom_bar(stat = "identity") +
  labs(title = "Average RETURN Rate by Sub-Grade", x = "Sub-Grade", y = "AVG RT Rate (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))




```



Are some loans paid back early? what proportion?  
  - calculate the actual loan term, i.e. the time by which a loan is fully paid back
What is the actual return from investment in a loan?
```{r}

#2.a.vi)


# Loan Purpose: Group loans by loan status and purpose, and count the number of loans per combination
loan_purpose_count <- lcdf %>% 
  group_by(loan_status, purpose) %>% 
  tally()
print(loan_purpose_count)

# Tabulate the loan status and purpose
table(lcdf$loan_status, lcdf$purpose)

# Loan Amount Variability by Purpose: Summarizing loan amounts by purpose
loan_purpose_summary <- lcdf %>%
  group_by(purpose) %>%
  summarise(
    defaults = sum(loan_status == "Charged Off", na.rm = TRUE),  
    total_loans = n(),  
    defaultrate = (defaults / total_loans) * 100,
    total_loan_amount = sum(loan_amnt, na.rm = TRUE),
    avg_loan_amount = mean(loan_amnt, na.rm = TRUE),
    min_interest_rate = min(int_rate, na.rm = TRUE),
    max_interest_rate = max(int_rate, na.rm = TRUE),
    avg_interest_rate = mean(int_rate, na.rm = TRUE),
    sd_interest_rate = sd(int_rate, na.rm = TRUE)
  )
print(loan_purpose_summary)

# Loan Grade by Purpose: Summarizing loan amounts and interest rates by grade and purpose
grade_purpose_summary <- lcdf %>%
  group_by(grade, purpose) %>%
  summarise(
    total_loan_amount = sum(loan_amnt, na.rm = TRUE),
    avg_loan_amount = mean(loan_amnt, na.rm = TRUE),
    min_interest_rate = min(int_rate, na.rm = TRUE),
    max_interest_rate = max(int_rate, na.rm = TRUE),
    avg_interest_rate = mean(int_rate, na.rm = TRUE),
    sd_interest_rate = sd(int_rate, na.rm = TRUE)
  )
print(grade_purpose_summary)

# Visualizing the results
# Plot histogram of interest rate by purpose
ggplot(lcdf, aes(x = int_rate, fill = purpose)) + 
  geom_histogram(binwidth = 1, position = "dodge") +
  labs(title = "Interest Rate Distribution by Loan Purpose", x = "Interest Rate", y = "Count")

# Plot bar chart of grade distribution by loan purpose
ggplot(lcdf, aes(x = grade, fill = purpose)) + 
  geom_bar(position = "dodge") +
  labs(title = "Grade Distribution by Loan Purpose", x = "Grade", y = "Count") +
  theme_minimal()


# Plot histogram of loan amount by purpose
ggplot(lcdf, aes(x = loan_amnt, fill = purpose)) + 
  geom_histogram(binwidth = 1000, position = "dodge") +
  labs(title = "Loan Amount Distribution by Loan Purpose", x = "Loan Amount", y = "Count")

# Plot loan amount by loan purpose and status
ggplot(lcdf, aes(x = loan_amnt, fill = purpose)) + 
  geom_histogram(binwidth = 1000) + 
  facet_wrap(~loan_status) +
  labs(title = "Loan Amount by Purpose and Loan Status", x = "Loan Amount", y = "Count")


# Loan Term Calculation: Convert last_pymnt_d to date type and add "01-" to it
lcdf$last_pymnt_d <- paste(lcdf$last_pymnt_d, "-01", sep = "")
lcdf$last_pymnt_d <- parse_date_time(lcdf$last_pymnt_d, "myd")

# Check the format of date columns
head(lcdf[, c("last_pymnt_d", "issue_d")])

# Loan Term Calculation: Calculate the loan term in years
lcdf$actualTerm <- ifelse(
  lcdf$loan_status == "Fully Paid", 
  as.numeric(difftime(lcdf$last_pymnt_d, lcdf$issue_d, units = "days")) / 365, 
  3  # Set to 3 years for Charged-Off loans
)

# Calculating the actual return
lcdf$actualReturn <- ifelse(
  lcdf$actualTerm > 0, 
  ((lcdf$total_pymnt - lcdf$funded_amnt) / lcdf$funded_amnt) * (1 / lcdf$actualTerm) * 100, 
  0
)

# Check some of the results
lcdf %>% 
  select(loan_status, int_rate, funded_amnt, total_pymnt, actualTerm, actualReturn) %>% 
  head()

# Summary statistics of actual return by loan status
return_summary <- lcdf %>%
  group_by(loan_status) %>%
  summarise(
    avg_actualReturn = mean(actualReturn, na.rm = TRUE),
    sd_actualReturn = sd(actualReturn, na.rm = TRUE)
  )
print(return_summary)



```


Some further analyses--exploration related to returns and performance
```{r}

#For cost-based performance, we may want to see the average interest rate, and the average of proportion of loan amount paid back, grouped by loan_status
lcdf%>% group_by(loan_status) %>% summarise(  intRate=mean(int_rate), totRet=mean((total_pymnt-funded_amnt)/funded_amnt)  )
# Notice that the totRet on Charged Off loans is negative, so, for every dollar invested, there is a loss (how much?).

#does this vary by loan_type?  Here, we are expressing totRet as a % value
lcdf%>% group_by(loan_status, grade) %>% summarise(  intRate=mean(int_rate),    
                                              totRet=mean((total_pymnt-funded_amnt)/funded_amnt)*100 )
     #Is this in line with what you'd expect (from loan grade info)?



# For Fully Paid loans, is the average value of totRet what you'd expect, considering the average value for intRate?
# Consider - if a loan were to be paid back over the full 3-year period, what would you expect for average expected total-return? And how does this compare with average of the actual totRet?
#(the totRet seems less than what may be  expected from intRate -- is this because many loans are paid back earlier).

#This summary can also help understand:
lcdf%>% group_by(loan_status) %>% summarise(  intRate=mean(int_rate), totRet=mean((total_pymnt-funded_amnt)/funded_amnt), avgActRet=mean(actualReturn)  )

#Another summary - by loan status and loan grade
lcdf%>% group_by(loan_status, grade) %>% summarise(  intRate=mean(int_rate),   
                                                  totRet=mean((total_pymnt-funded_amnt)/funded_amnt),
                                                  avgActRet=mean(actualReturn),avgActTerm=mean(actualTerm)  )

#you may like to look at some of these variables
lcdf %>% select(loan_status, loan_amnt, funded_amnt, total_pymnt, int_rate, actualTerm, actualReturn ) %>% view()

#some more summaries
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgRet=mean(annRet), avgActualRet=mean(actualReturn)*100, avgActualTerm=mean(actualTerm),  minActualRet=min(actualReturn)*100, maxActualRet=max(actualReturn)*100)

lcdf %>% group_by(loan_status) %>% summarise(nLoans=n(), avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgRet=mean(annRet), avgActualRet=mean(actualReturn)*100, avgActualTerm=mean(actualTerm),  minActualRet=min(actualReturn)*100, maxActualRet=max(actualReturn)*100)


```




Further data exploration -- look into emp_length
```{r}
#2.a.vii)

# Group by employment length and count occurrences of each value
emp_length_counts <- lcdf %>% 
  group_by(emp_length) %>% 
  tally()

print(emp_length_counts)

# Convert emp_length to factor with ordered levels
lcdf$emp_length <- factor(lcdf$emp_length, levels=c("n/a", "< 1 year", "1 year", "2 years", "3 years", "4 years", "5 years", "6 years", "7 years", "8 years", "9 years", "10+ years"))

# Check the table of loan status by employment length
loan_status_emp_length <- table(lcdf$loan_status, lcdf$emp_length)
print(loan_status_emp_length)

# Calculate the proportion of Charged Off loans for each level of employment length
cc <- loan_status_emp_length
charged_off_proportions <- cc[1,] / (cc[1,] + cc[2,])
print(charged_off_proportions)

# Check the table of loan grade by employment length
loan_grade_emp_length <- table(lcdf$grade, lcdf$emp_length)
print(loan_grade_emp_length)

# Additional summary statistics by employment length
emp_length_summary <- lcdf %>%
  group_by(emp_length) %>%
  summarise(
    nLoans = n(),
    defaults = sum(loan_status == "Charged Off"),
    defaultRate = defaults / nLoans,
    avgIntRate = mean(int_rate, na.rm = TRUE),
    avgLoanAmt = mean(loan_amnt, na.rm = TRUE),
    avgActRet = mean(actualReturn, na.rm = TRUE),
    avgActTerm = mean(actualTerm, na.rm = TRUE)
  )

print(emp_length_summary)

# Bar Plot of Default Rates by Employment Length
ggplot(emp_length_summary, aes(x = emp_length, y = defaultRate)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Default Rates by Employment Length", x = "Employment Length", y = "Default Rate") +
  theme_minimal()

# Box Plot of Average Loan Amount by Employment Length
ggplot(lcdf, aes(x = emp_length, y = loan_amnt)) +
  geom_boxplot(fill = "lightgreen") +
  labs(title = "Loan Amount Distribution by Employment Length", x = "Employment Length", y = "Loan Amount") +
  theme_minimal()



```


Further data exploration -- look into loan purpose
```{r}
# Does default rate, int-rate, etc vary by loan purpose
lcdf %>% group_by(purpose) %>% tally()
lcdf %>% group_by(purpose) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgIntRate=mean(int_rate),  avgLoanAmt=mean(loan_amnt),  avgActRet = mean(actualReturn), avgActTerm=mean(actualTerm))

#Does loan-grade vary by purpose?
table(lcdf$purpose, lcdf$grade)


#some other detailed analyses
#Does loan purpose relate to emp_length?
table(lcdf$purpose, lcdf$emp_length)

#do those with home-improvement loans own or rent a home?
table(lcdf$home_ownership, lcdf$purpose)



lcdf %>% group_by(purpose) %>% tally()
#some of category levels have very few examples 
#    do you want to recode such categories with very few cases to "other"
lcdf$purpose <- fct_recode(lcdf$purpose, other="wedding", other="educational", other="renewable_energy")


#Plot of loan amount by purpose
boxplot(lcdf$loan_amnt ~ lcdf$purpose)

```




Some derived attributes
```{r}
#.2.a.viii)
# Deriving ability to payback as the ratio of annual income and annual payment to be made
lcdf$ability_to_payback <- lcdf$annual_inc / (lcdf$installment * 12)

# Deriving proportion of satisfactory bankcard accounts
lcdf$prop_SatisBC_Accnts <- ifelse(lcdf$num_bc_tl > 0, lcdf$num_bc_sats / lcdf$num_bc_tl, 0)

# Deriving first year payment ability
lcdf$firstyr_pymnt_ability <- lcdf$total_bal_ex_mort / (lcdf$installment * 12)

# Deriving Credit Utilization Ratio (CUR)
lcdf$credit_utilization <- lcdf$total_bc_limit / (lcdf$total_bc_limit + lcdf$total_bal_ex_mort)

# Analyzing relationships by loan grade
# Ability to payback analysis
payback_analysis <- lcdf %>% 
  group_by(grade) %>% 
  summarise(
    nLoans = n(),
    defaults = sum(loan_status == "Charged Off"),
    defaultRate = defaults / nLoans,
    avgAbilityToPayback = mean(ability_to_payback, na.rm = TRUE)
  )

# Satisfactory bankcard accounts analysis
bankcard_analysis <- lcdf %>% 
  group_by(grade) %>% 
  summarise(
    nLoans = n(),
    defaults = sum(loan_status == "Charged Off"),
    defaultRate = defaults / nLoans,
    avgPropSatisBC_Accnts = mean(prop_SatisBC_Accnts, na.rm = TRUE)
  )

# First year payment ability analysis
first_year_payment_analysis <- lcdf %>% 
  group_by(grade) %>% 
  summarise(
    nLoans = n(),
    defaults = sum(loan_status == "Charged Off"),
    defaultRate = defaults / nLoans,
    avgFirstYrPaymentAbility = mean(firstyr_pymnt_ability, na.rm = TRUE)
  )

# Credit Utilization Ratio analysis
cur_analysis <- lcdf %>% 
  group_by(grade) %>% 
  summarise(
    nLoans = n(),
    defaults = sum(loan_status == "Charged Off"),
    defaultRate = defaults / nLoans,
    avgCreditUtilization = mean(credit_utilization, na.rm = TRUE)
  )

# Combine all analyses into a single data frame
combined_analysis <- payback_analysis %>%
  left_join(bankcard_analysis, by = "grade", suffix = c("_payback", "_bankcard")) %>%
  left_join(first_year_payment_analysis, by = "grade") %>%
  left_join(cur_analysis, by = "grade")

# View combined analysis
print(combined_analysis)  

# Summary table with selected variables
summary_table <- lcdf %>%
  group_by(grade) %>%
  summarise(
    nLoans = n(),
    defaults = sum(loan_status == "Charged Off"),
    defaultRate = defaults / nLoans,
    avgAbilityToPayback = mean(ability_to_payback, na.rm = TRUE),
    avgPropSatisBC_Accnts = mean(prop_SatisBC_Accnts, na.rm = TRUE),
    avgFirstYrPaymentAbility = mean(firstyr_pymnt_ability, na.rm = TRUE),
    avgCreditUtilization = mean(credit_utilization, na.rm = TRUE)
  )

# Print the summary table
print(summary_table)

# Optionally, you can save it as a CSV file
write.csv(summary_table, "summary_table.csv", row.names = FALSE)

#filter null
lcdf_filtered <- lcdf %>%
  filter(is.finite(credit_utilization))

# Ability to Payback by Loan Grade
ggplot(lcdf, aes(x = grade, y = ability_to_payback, fill = grade)) +
  geom_boxplot() +
  labs(title = "Ability to Payback by Loan Grade",
       x = "Loan Grade",
       y = "Ability to Payback (Annual Income / Annual Payment)") +
  theme_minimal()

# Proportion of Satisfactory Bankcard Accounts by Loan Grade
ggplot(lcdf, aes(x = grade, y = prop_SatisBC_Accnts, fill = grade)) +
  geom_boxplot() +
  labs(title = "Proportion of Satisfactory Bankcard Accounts by Loan Grade",
       x = "Loan Grade",
       y = "Proportion of Satisfactory Bankcard Accounts") +
  theme_minimal()

# Credit Utilization Ratio by Loan Status (filtered data)
ggplot(lcdf_filtered, aes(x = loan_status, y = credit_utilization, fill = loan_status)) +
  geom_boxplot() +
  labs(title = "Credit Utilization Ratio by Loan Status",
       x = "Loan Status",
       y = "Credit Utilization Ratio") +
  theme_minimal()





```


Converting character variables
```{r}

glimpse(lcdf)

#  notice that there are a few character type variables - grade, sub_grade, verification_status,....
#   We can  convert all of these to factor
lcdf <- lcdf %>% mutate_if(is.character, as.factor)

```




Drop some variables for potential leakage, others
```{r}

#2c)
# Print the initial dimensions of the dataset
initial_dimensions <- dim(lcdf)
cat("Initial dimensions of the dataset:", initial_dimensions, "\n")

# Count the number of variables before removal
initial_variable_count <- ncol(lcdf)

# Define variables to remove that may cause leakage or are not useful for predictive modeling
varsToRemove <- c(
  'funded_amnt_inv', 
  'term', 
  'emp_title', 
  'pymnt_plan', 
  'earliest_cr_line', 
  'title', 
  'zip_code', 
  'addr_state', 
  'out_prncp', 
  'out_prncp_inv', 
  'total_pymnt_inv', 
  'total_rec_prncp', 
  'total_rec_int', 
  'total_rec_late_fee', 
  'recoveries', 
  'collection_recovery_fee', 
  'last_credit_pull_d', 
  'policy_code', 
  'disbursement_method', 
  'debt_settlement_flag', 
  'settlement_term', 
  'application_type'
)

# Remove the specified variables from the dataset
lcdf <- lcdf %>% select(-all_of(varsToRemove))

# Drop variables that may cause leakage, starting with "hardship"
lcdf <- lcdf %>% select(-starts_with("hardship"))

# Drop variables that may cause leakage, starting with "settlement"
lcdf <- lcdf %>% select(-starts_with("settlement"))

# Additional variables to drop that may not be useful for analysis
varsToRemove2 <- c("last_pymnt_d", "last_pymnt_amnt", "issue_d")
lcdf <- lcdf %>% select(-all_of(varsToRemove2))

# Print the dimensions of the dataset after dropping variables
final_dimensions <- dim(lcdf)
cat("Dimensions of the dataset after variable removal:", final_dimensions, "\n")

# Count the number of variables after removal
final_variable_count <- ncol(lcdf)

# Create a data frame for plotting
variable_count <- data.frame(
  Category = c("Before Removal", "After Removal"),
  Count = c(initial_variable_count, final_variable_count)
)

# Plot the number of variables before and after removal
ggplot(variable_count, aes(x = Category, y = Count, fill = Category)) +
  geom_bar(stat = "identity") +
  labs(title = "Number of Variables Before and After Removal",
       x = "Dataset State",
       y = "Number of Variables") +
  theme_minimal()

# Optional: Save the cleaned dataset for future use
# write.csv(lcdf, "cleaned_dataset.csv", row.names = FALSE)

# Display the remaining variables to confirm the changes
glimpse(lcdf)


```




Missing values
Think through potential reasons for missing values in different variables?
Are some of the missing values actually 'zeros' which are not recorded in the data?
Is missing-ness informative in some way?  Are there, for example,  more/less defaults for cases where values on the attribute are missing ?
```{r}

#2b)
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(VIM)  # For visualizing missing data

# Step 1: Drop variables with all empty values
lcdf <- lcdf %>% select_if(function(x) { !all(is.na(x)) })

# Check how many variables were dropped (compare dimensions before and after)
dim(lcdf)

# Step 2: Identify remaining columns with missing values
names(lcdf)[colSums(is.na(lcdf)) > 0]

# Plot Missing Values: Visualizing missing data pattern
aggr_plot <- aggr(lcdf, col=c('navyblue', 'red'), numbers=TRUE, sortVars=TRUE, 
                  labels=names(lcdf), cex.axis=.7, gap=3, 
                  ylab=c("Missing data","Pattern"))

# Step 3: Get missing value proportions in each column
missing_proportions <- colMeans(is.na(lcdf))
missing_proportions[missing_proportions > 0]  # Only display columns with missing values

# Visualize the proportion of missing values
missing_data <- data.frame(Variable = names(missing_proportions), 
                           Missing_Proportion = missing_proportions)
ggplot(missing_data, aes(x = reorder(Variable, -Missing_Proportion), y = Missing_Proportion)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() + 
  ylab("Proportion of Missing Values") +
  xlab("Variables") + 
  ggtitle("Proportion of Missing Values by Variable") +
  theme_minimal()

# Step 4: Handle specific variables with large proportions of missing values

# For `open_acc_6m`, which has 97% missing
summary(as.factor(lcdf$open_acc_6m))  # Check distribution
table(replace_na(lcdf$open_acc_6m, 0))  # Replace missing values with 0

# Visualize the proportion of ChargedOff by open_acc_6m
cc <- table(lcdf$loan_status, replace_na(lcdf$open_acc_6m, 0))
barplot(cc[1,] / (cc[2,] + cc[1,]), ylab = "Prop ChargedOff", main = "Prop ChargedOff by open_acc_6m", col = "lightblue")

# For `mths_since_last_record`, which has more than 80% missing values
cc <- table(lcdf$loan_status, replace_na(lcdf$mths_since_last_record, NA))  # Keep as NA
cc[1,] / (cc[2,] + cc[1,])

# For `mths_since_last_delinq`, which has around 50% missing values
cc <- table(lcdf$loan_status, replace_na(lcdf$mths_since_last_delinq, NA))  # Keep as NA
cc[1,] / (cc[2,] + cc[1,])

# For `mths_since_recent_inq`, which has around 10% missing
cc <- table(lcdf$loan_status, replace_na(lcdf$mths_since_recent_inq, NA))
cc[1,] / (cc[2,] + cc[1,])

# Step 5: Remove variables with more than 60% missing values
nm <- names(lcdf)[colMeans(is.na(lcdf)) > 0.6]
lcdf <- lcdf %>% select(-all_of(nm))

# Step 6: Impute missing values for the remaining variables
# - First, get the columns with missing values
nm <- names(lcdf)[colSums(is.na(lcdf)) > 0]
summary(lcdf[, nm])

# For bc_open_to_buy, replace missing values by the median
lcx <- lcdf[, c(nm)]
lcx <- lcx %>% replace_na(list(bc_open_to_buy = median(lcx$bc_open_to_buy, na.rm = TRUE)))

# Now apply imputation to the main dataset `lcdf`
lcdf <- lcdf %>% replace_na(list(
  mths_since_last_delinq = -500,   # Use -500 for missing values in delinquency-related variables
  bc_open_to_buy = median(lcdf$bc_open_to_buy, na.rm = TRUE), 
  mo_sin_old_il_acct = 1000,  # Use placeholder values where appropriate
  mths_since_recent_bc = 1000, 
  mths_since_recent_inq = 50, 
  num_tl_120dpd_2m = median(lcdf$num_tl_120dpd_2m, na.rm = TRUE), 
  percent_bc_gt_75 = median(lcdf$percent_bc_gt_75, na.rm = TRUE), 
  bc_util = median(lcdf$bc_util, na.rm = TRUE)
))

# Step 7: Ensure all missing values are handled
colMeans(is.na(lcdf))[colMeans(is.na(lcdf)) > 0]

# Step 8: Final step to replace missing values in numeric columns by median
lcdf <- lcdf %>% mutate_if(is.numeric, ~ifelse(is.na(.x), median(.x, na.rm = TRUE), .x))

# Final dimensions check
dim(lcdf)  # Check how many variables are left

# Visualization of how the data has been cleaned
# Example: Distribution of `bc_open_to_buy` before and after imputation
ggplot(lcdf, aes(x = bc_open_to_buy)) + 
  geom_histogram(fill = "lightblue", color = "black", bins = 30) + 
  ggtitle("Distribution of `bc_open_to_buy` After Imputation") +
  theme_minimal()


```





Univariate analyses - which variables are individually predictive of the outcome ?
Considering a single variable model to predict loan_status, what could be a measure of performance?  AUC? 
For a univariate model with a variable, say, x1, what should we consider as the model 'score' for predicting loan_status? 
Can we take the values of x1 as the score for a model y_hat=f(x1) ? 

Using this approximate approach, we can then compute the AUC for each variable
```{r}
#3
# Load the necessary libraries
library(tidyverse)
library(readxl)
library(pROC)
library(broom)
library(magrittr)
library(corrplot)
library(ggplot2)
library(caret)


# Convert loan_status to a binary factor (0 = Charged Off, 1 = Fully Paid)
lcdf$loan_status <- as.numeric(factor(lcdf$loan_status, levels = c("Charged Off", "Fully Paid")))

# Check the structure of the data
str(lcdf)

# List of continuous variables to analyze
continuous_vars <- c("loan_amnt", "int_rate", "annual_inc", "dti")

# List of categorical variables to analyze
categorical_vars <- c("grade", "sub_grade", "emp_length", "purpose")

# ============================
# Correlation & Chi-Square Test
# ============================

# Function to compute point-biserial correlation for continuous variables
point_biserial_corr <- function(x, y) {
  cor(x, y, method = "pearson")
}

# Apply correlation function to continuous variables
continuous_correlations <- sapply(lcdf[continuous_vars], function(x) point_biserial_corr(x, lcdf$loan_status))

# Display the point-biserial correlations
continuous_correlations

# Function to compute chi-square test for categorical variables
chi_square_test <- function(x, y) {
  tbl <- table(x, y)
  chisq.test(tbl)$p.value
}

# Apply chi-square test to categorical variables
categorical_chisq_results <- sapply(lcdf[categorical_vars], function(x) chi_square_test(x, lcdf$loan_status))

# Display the chi-square p-values
categorical_chisq_results

# ====================================
# Visualizations for Univariate Analysis
# ====================================


# ====================
# AUC-Based Approach
# ====================

# Convert factor variables to numeric for AUC calculation
lcdf_numeric <- lcdf %>% 
  mutate_if(is.factor, as.numeric)

# Calculate AUC for numeric variables only
aucsNum <- sapply(lcdf_numeric %>% select_if(is.numeric), auc, response = lcdf$loan_status)

# Filter variables with AUC > 0.5 (variables with predictive power)
predictive_vars <- aucsNum[aucsNum > 0.5]
print(predictive_vars)

# Convert the results into a data frame and display them in sorted order
tidy_aucs <- data.frame(variable = names(predictive_vars), auc_value = predictive_vars)
tidy_aucs %>% arrange(desc(auc_value)) %>% View()  # Correct 'View' with a capital 'V'

# Check for potential data leakage by identifying variables with high AUC (>0.9)
high_auc_vars <- tidy_aucs %>% filter(auc_value > 0.9)
print(high_auc_vars)

# Example: Manually check the AUC for specific variables (numeric/factor variables)
auc(response = lcdf$loan_status, lcdf$loan_amnt)  # AUC for loan amount
auc(response = lcdf$loan_status, as.numeric(lcdf$emp_length))  # AUC for employment length

# For the numeric variables (apply AUC to all numeric variables)
aucsNum <- sapply(lcdf %>% select_if(is.numeric), auc, response = lcdf$loan_status)

# Consider both numeric and factor variables for AUC calculation
aucAll <- sapply(lcdf %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), auc, response = lcdf$loan_status)

# Display variables with AUC > 0.5 (useful predictors)
aucAll[aucAll > 0.5]

# Convert to tidy format using broom package
tidy(aucAll[aucAll > 0.5]) %>% View()

# Display in sorted order
tidy(aucAll) %>% arrange(desc(aucAll))%>% view()


# Identify and evaluate variables with very high AUC (potential data leakage)
high_aucAll_vars <- tidy(aucAll) %>% filter(aucAll > 0.6)
print(high_aucAll_vars)

# Example: actualReturn, actualTerm are variables that could indicate leakage.

#We can see that annual return and total payment can cause issue here

```





Next we will build some predictive models


Split the data into trn, text subsets
```{r}
#4 

TRNPROP = 0.5  #proportion of examples in the training sample

nr<-nrow(lcdf)
trnIndex<- sample(1:nr, size = round(TRNPROP * nr), replace=FALSE)

lcdfTrn <- lcdf[trnIndex, ]
lcdfTst <- lcdf[-trnIndex, ]

```





DT models using rpart
```{r}

#Do you want to use all the variables in the dataset as predictors ?
#Take a look at teh data
glimpse(lcdf)

#Are are some variable you want to exclude  - due to leakage, or other reasons?
#  What about variables like actualTerm, actualReturn, ... which you calculated?
#       These will be useful in performance assessment, but should not be used in building the model.
#Are there any data variables which you may not want to use in developing the model?


#varsOmit <- c('actualTerm', 'actualReturn', 'annRet', 'total_pymnt')  #are there others?
varsOmit <- c('annRet', 'total_pymnt')


library(rpart)


lcDT1 <- rpart(loan_status ~., data=lcdfTrn %>% select(-all_of(varsOmit)), method="class", parms = list(split = "information"), control = rpart.control(minsplit = 30))
printcp(lcDT1)  #reasonable ?  (If the tree does not grow at all, maybe set a lower value of cp?)

#variable importance
lcDT1$variable.importance
  # Does this look reasonable?  Any leakage causing variables can show up as highly important !!
  #  Make sure you remove any leakage variables (include in varsOmit above)


lcDT1 <- rpart(loan_status ~., data=lcdfTrn %>% select(-all_of(varsOmit)), method="class", parms = list(split = "information"), control = rpart.control(cp=0.0001, minsplit = 50))


#Do we want to prune the tree -- check for performance with different cp levels
printcp(lcDT1)
lcDT1p<- prune.rpart(lcDT1, cp=0.0003)   
     #Note: this value of cp used here is just as an example. You should select the best cp value based on rpart cpTable 

#......
#the optimal xerror is the min_error+xstd
mincp_i <- as.numeric(which.min(lcDT1$cptable[, "xerror"]))
optError <- lcDT1$cptable[mincp_i, "xerror"]+lcDT1$cptable[mincp_i, "xstd"]

#the row(index) of the xerror value which is closet to optError
optCP_i <- which.min(abs(lcDT1$cptable[,"xerror"]- optError))

#finally, get the best cp value corresponding to optCP_i
optCP <- lcDT1$cptable[optCP_i, "CP"]
optCP

printcp(lcDT1)

#Training the model considering a more balanced training dataset?
#Use the 'prior' parameters -- to account for unbalanced training data
#The 'prior' parameter can be used to specify the distribution of examples across classes.  By default, the prior is taken from the dataset
#For rpart to consider a balanced distribution:
lcDT1b <- rpart(loan_status ~., data=lcdfTrn %>% select(-all_of(varsOmit)), 
               method="class", parms = list(split = "gini", prior=c(0.5, 0.5)), 
               control = rpart.control(cp=0.0, minsplit = 20, minbucket = 10, maxdepth = 20,  xval=10) )

#find best cp and prune

printcp(lcDT1b)
lcDT1bp<- prune.rpart(lcDT1b, cp=0.0003)

printcp(lcDT1b)
```



Performance evaluation
```{r}

#Evaluate performance
predTrn=predict(lcDT1,lcdfTrn, type='class')
table(pred = predTrn, true=lcdfTrn$loan_status)
mean(predTrn == lcdfTrn$loan_status)
table(pred = predict(lcDT1,lcdfTst, type='class'), true=lcdfTst$loan_status)
mean(predict(lcDT1,lcdfTst, type='class') ==lcdfTst$loan_status)

#With a different classification threshold
CTHRESH=0.3
predProbTrn=predict(lcDT1,lcdfTrn, type='prob')
predProbTrn
predTrnCT = ifelse(predProbTrn[, '2'] > CTHRESH, 'Charged Off', 'Fully Paid')
table(predTrnCT , true=lcdfTrn$loan_status)

predProbTst=predict(lcDT1,lcdfTst, type='prob')
predTstCT = ifelse(predProbTst[, '2'] > CTHRESH, 'Charged Off', 'Fully Paid')
table(predTstCT , true=lcdfTst$loan_status)

# Or, to set the predTrnCT values as factors, and then get the confusion matrix
table(predictions=factor(predTrnCT, levels=c("Fully Paid", "Charged Off")), actuals=lcdfTrn$loan_status)



#Or you can use the confusionMatrix function from the caret package
predTrn <- factor(predTrn, levels = c("Fully Paid", "Charged Off"))
lcdfTrn$loan_status <- factor(lcdfTrn$loan_status, levels = c("1", "2"))
predTrn <- factor(predTrn, levels = levels(lcdfTrn$loan_status))

# Check if levels match between the two factors
if (!all(levels(predTrn) == levels(lcdfTrn$loan_status))) {
  stop("Levels of prediction and reference factors do not match.")
}

# Now calculate the confusion matrix
library(caret)
confusion_matrix <- confusionMatrix(predTrn, lcdfTrn$loan_status)
print(confusion_matrix)
    #if you get an error saying that the 'e1071' package is required, 
    # you should install and load that too
#Notice that the output says 
#   'Positive' class: Fully Paid
#So,the confusionMatrix based performance measures are based 
#  on the "Fully Paid" class as the class of interest.
# If you want to get performance measure for "Charged Off", use 
#    the positive- paremeter
confusionMatrix(predTrn, lcdfTrn$loan_status, positive="1")

#For the test data?


#ROC plot
library(ROCR)

score=predict(lcDT1b,lcdfTst, type="prob")[,"2"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("1", "2"))
    #label.ordering here specifies the 'negative', 'positive' class labels   

#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf)
abline(a=0, b= 1)

#AUC value
aucPerf=performance(pred, "auc")
aucPerf@y.values


#Lift curve
liftPerf <-performance(pred, "lift", "rpp")
plot(liftPerf)

lcDT1b$variable.importance



```





To develop C50 models, you can write R code similar to that in the earlier example with the mortgageDefaulters dataset
```{r}





```




Write functions which we can easily call for performance evaluation of different models (rather than repeatedly write multiple lines of code)
```{r}




  
```





Random forest models
```{r}

library(ranger)
#for trees=200
varsOmit <- c('annRet', 'total_pymnt')

rfModel1 <- ranger(loan_status ~., data=lcdfTrn %>%  select(-all_of(varsOmit)), num.trees = 200, importance='permutation', probability = TRUE)

#variable importance
vimp_rfGp<-importance(rfModel1)
vimp_rfGp

#Get the predictions -- look into the returned object
scoreTrn <- predict(rfModel1,lcdfTrn)
head(scoreTrn$predictions)

#classification performance , at specific threshold 
table(pred = scoreTrn$predictions[, 2] > 0.7, actual=lcdfTrn$loan_status)

scoreTst <- predict(rfModel1,lcdfTst)
table(pred = scoreTst$predictions[, 2] > 0.7, actual=lcdfTst$loan_status)



#ROC curve, AUC
str(scoreTrn$predictions)
# Generate prediction object using the second column for "Fully Paid"
pred <- prediction(scoreTrn$predictions[, 2], lcdfTrn$loan_status, label.ordering = c("1", "2"))
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf)
abline(a=0, b= 1)

#AUC value
aucPerf=performance(pred, "auc")
sprintf("AUC: %f", aucPerf@y.values)


#Or call the performance function defined above
#fnROCPerformance(predict(rfModel2,lcdfTst)$predictions[,"Fully Paid"], dat=lcdfTst)

#for decile defaults-lift performance
#fnDecileLiftsPerformance_defaults( predict(rfModel1,lcdfTrn)$predictions[,"Charged Off"], lcdfTrn  )
     #Note- this function calculates lifts for the minority class - so score should be prob of "charged off'

#for decile returns performance
#fnDecileReturnsPerformance( predict(rfModel1,lcdfTrn)$predictions[,"Fully Paid"], lcdfTrn  )
     #do you understand why we  provide scores for "Fully Paid" here?




#Different parameters for random forest - for example, if the default model is seen to overfit
rfModel2 <- ranger(loan_status ~., data=lcdfTrn %>%  select(-all_of(varsOmit)),
                   num.trees =500, probability = TRUE, min.node.size = 50, max.depth = 15, importance='permutation')
#     min.node.size,  max.depth

#variable importance
vimp_rfGp<-importance(rfModel2)
vimp_rfGp

#Get the predictions -- look into the returned object
scoreTrn <- predict(rfModel2,lcdfTrn)
head(scoreTrn$predictions)

#classification performance , at specific threshold 
table(pred = scoreTrn$predictions[, 2] > 0.7, actual=lcdfTrn$loan_status)

scoreTst <- predict(rfModel2,lcdfTst)
table(pred = scoreTst$predictions[, 2] > 0.7, actual=lcdfTst$loan_status)

#     look up https://www.rdocumentation.org/packages/ranger/versions/0.13.1/topics/ranger


# Check levels to confirm
print(levels(lcdfTrn$loan_status))

# Re-run the model after confirming `loan_status` setup
rfModel3 <- ranger(
  loan_status ~ ., 
  data = lcdfTrn %>% select(-all_of(varsOmit)), 
  num.trees = 500, 
  class.weights = c(6, 1),  # Higher weight for "Charged Off"
  importance = 'permutation', 
  probability = TRUE
)


#variable importance
vimp_rfGp<-importance(rfModel3)
vimp_rfGp 

#Get the predictions -- look into the returned object
scoreTrn <- predict(rfModel3,lcdfTrn)
head(scoreTrn$predictions)

#classification performance , at specific threshold 
table(pred = scoreTrn$predictions[, 2] > 0.7, actual=lcdfTrn$loan_status)

scoreTst <- predict(rfModel3,lcdfTst)
table(pred = scoreTst$predictions[, 2] > 0.7, actual=lcdfTst$loan_status)

#        "Weights for the outcome classes (in order of the factor levels) in the splitting rule (cost sensitive learning). For classification the weights are also applied in the majority vote in terminal nodes".
#     look up https://www.rdocumentation.org/packages/ranger/versions/0.13.1/topics/ranger






```


```{r}

# Load necessary libraries
library(xgboost)
library(caret)
library(ROCR)

# Assuming lcdfTrn is the full dataset; load if necessary
# lcdfTrn <- read.csv("path_to_your_data.csv")

# Step 1: Data Preparation

# Ensure that `loan_status` is a factor
lcdfTrn$loan_status <- as.factor(lcdfTrn$loan_status)

# Create dummy variables for predictors in the dataset
fdum <- dummyVars(~ ., data = lcdfTrn %>% select(-loan_status))
dxlcdf <- predict(fdum, lcdfTrn)

# Convert `loan_status` to a binary target variable
dylcdf <- class2ind(lcdfTrn$loan_status, drop2nd = FALSE)  # One-hot encoding
colcdf <- dylcdf[, 1]  # Assuming "Fully Paid" is the target class

TRNPROP <- 0.5  # proportion of examples in the training sample

# Ensure `dxlcdf` exists and matches row count with `lcdf`
nr <- nrow(dxlcdf)  # Use `dxlcdf` row count for `trnIndex`
trnIndex <- sample(1:nr, size = round(TRNPROP * nr), replace = FALSE)

# Split predictors and target for training and test sets
dxlcdfTrn <- dxlcdf[trnIndex, ]
colcdfTrn <- colcdf[trnIndex]
dxlcdfTst <- dxlcdf[-trnIndex, ]
colcdfTst <- colcdf[-trnIndex]

# Remove columns that may cause leakage
dxlcdfTrn_filtered <- dxlcdfTrn[, !colnames(dxlcdfTrn) %in% c("total_pymnt", "annRet")]
dxlcdfTst_filtered <- dxlcdfTst[, !colnames(dxlcdfTst) %in% c("total_pymnt", "annRet")]

# Create XGBoost DMatrix objects for training and testing
dTrn <- xgb.DMatrix(data = dxlcdfTrn_filtered, label = colcdfTrn)
dTst <- xgb.DMatrix(data = dxlcdfTst_filtered, label = colcdfTst)

# Watchlist for monitoring training and test performance
xgbWatchlist <- list(train = dTrn, eval = dTst)

# Step 2: Initial XGBoost Model Training with Early Stopping

# Set initial parameters for XGBoost
xgbParam <- list(
  max_depth = 5,
  eta = 0.01,
  objective = "binary:logistic",
  eval_metric = "error",
  eval_metric = "auc"
)

# Train the model with early stopping based on evaluation metrics
xgb_lsM1 <- xgb.train(
  params = xgbParam,
  data = dTrn,
  nrounds = 500,
  watchlist = xgbWatchlist,
  early_stopping_rounds = 10
)

# Display the best iteration from early stopping
best_iteration <- xgb_lsM1$best_iteration
cat("Best Iteration from Early Stopping:", best_iteration, "\n")

# Step 3: Model Prediction and Evaluation

# Predict on training set and create confusion matrix
xpredTrg <- predict(xgb_lsM1, dTrn)
table(pred = as.numeric(xpredTrg > 0.5), actual = colcdfTrn)

# Predict on test set and calculate ROC, AUC
xpredTst <- predict(xgb_lsM1, dTst)
pred_xgb_lsM1 <- prediction(xpredTst, colcdfTst)
aucPerf_xgb_lsM1 <- performance(pred_xgb_lsM1, "tpr", "fpr")
plot(aucPerf_xgb_lsM1, main = "ROC Curve for XGBoost Model")
abline(a = 0, b = 1)

#CONFUSION MATRIX FOR tstdata
table(pred = as.numeric(xpredTst > 0.5), actual = colcdfTst)

# AUC value
auc_value <- performance(pred_xgb_lsM1, "auc")
cat("AUC:", auc_value@y.values[[1]], "\n")

# Step 4: Cross-Validation to Tune Model Parameters

# Update parameters for cross-validation
xgbParam <- list(
  max_depth = 3,
  eta = 0.1,
  objective = "binary:logistic",
  eval_metric = "error",
  eval_metric = "auc"
)

# Perform cross-validation to tune parameters
xgb_lscv <- xgb.cv(
  params = xgbParam,
  data = dTrn,
  nrounds = 500,
  nfold = 5,
  early_stopping_rounds = 10,
  verbose = 0
)

# Best iteration from cross-validation
best_cvIter <- xgb_lscv$best_iteration
cat("Best Iteration from Cross-Validation:", best_cvIter, "\n")

# Step 5: Final Model Training with Optimal Parameters

# Train the final model using the best iteration
xgb_lsbest <- xgb.train(
  params = xgbParam,
  data = dTrn,
  nrounds = best_cvIter
)

# Step 6: Variable Importance Analysis

# Plot variable importance for the final model
importance_matrix <- xgb.importance(model = xgb_lsbest)
xgb.plot.importance(importance_matrix, main = "Variable Importance - XGBoost Model")

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}

#8. Develop models to identify loans which provide the best returns. Explain how you define returns? Does it include Lending Clubs service costs? Develop glm, rf, gbm (xgb) models for this. Show how you systematically experiment with different parameters to find the best models. Compare model performance.

# Load necessary libraries
library(dplyr)
library(caret)
library(ranger)
library(glmnet)
library(gbm)

# Assuming `lcdf` is your full dataset; uncomment and adjust if loading from a CSV
# lcdf <- read.csv("path_to_your_data.csv")

# Define return value as (total payments - funded amount) / funded amount
lcdf$ret_value <- (lcdf$total_pymnt - lcdf$funded_amnt) / lcdf$funded_amnt

# Set seed for reproducibility
set.seed(123)

# Split the data into 70% training and 30% test sets
train_index <- createDataPartition(lcdf$ret_value, p = 0.7, list = FALSE)
lcdfrps_trn <- lcdf[train_index, ]
lcdfrps_tst <- lcdf[-train_index, ]

# Confirm the dimensions of the split
cat("Training set dimensions:", dim(lcdfrps_trn), "\n")
cat("Test set dimensions:", dim(lcdfrps_tst), "\n")

# Step 1: Random Forest Model to Predict Returns
rfLC_Ret <- ranger(
  ret_value ~ ., 
  data = lcdfrps_trn %>% select(-annRet), 
  num.trees = 200, 
  importance = 'permutation'
)

# Predictions on training and test sets for Random Forest
rfLC_Pred_Ret_trn <- predict(rfLC_Ret, lcdfrps_trn)
rfLC_Pred_Ret_tst <- predict(rfLC_Ret, lcdfrps_tst)

# Calculate RMSE for Random Forest
rf_rmse_trn <- sqrt(mean((rfLC_Pred_Ret_trn$predictions - lcdfrps_trn$ret_value)^2))
rf_rmse_tst <- sqrt(mean((rfLC_Pred_Ret_tst$predictions - lcdfrps_tst$ret_value)^2))

# Plot predicted vs actual returns for training and test sets
plot(rfLC_Pred_Ret_trn$predictions, lcdfrps_trn$ret_value, main = "RF Predicted vs Actual Returns (Train)")
plot(rfLC_Pred_Ret_tst$predictions, lcdfrps_tst$ret_value, main = "RF Predicted vs Actual Returns (Test)")

# Step 2: GLM Model to Predict Returns
# Prepare matrices for GLM
xD_ret_trn <- data.matrix(lcdfrps_trn %>% select(-annRet, -ret_value))
xD_ret_tst <- data.matrix(lcdfrps_tst %>% select(-annRet, -ret_value))

# Train GLM model using cross-validated glmnet
glmRet <- cv.glmnet(
  xD_ret_trn, 
  lcdfrps_trn$ret_value, 
  family = "gaussian"
)

# Predictions on training and test sets for GLM
glmPredRet_trn <- predict(glmRet, xD_ret_trn)
glmPredRet_tst <- predict(glmRet, xD_ret_tst)

# Calculate RMSE for GLM
glm_rmse_trn <- sqrt(mean((glmPredRet_trn - lcdfrps_trn$ret_value)^2))
glm_rmse_tst <- sqrt(mean((glmPredRet_tst - lcdfrps_tst$ret_value)^2))

# Plot predicted vs actual returns for GLM
plot(glmPredRet_trn, lcdfrps_trn$ret_value, main = "GLM Predicted vs Actual Returns (Train)")
plot(glmPredRet_tst, lcdfrps_tst$ret_value, main = "GLM Predicted vs Actual Returns (Test)")

# Step 3: GBM Model to Predict Returns
# Convert necessary categorical variables to factors for GBM
lcdfrps_trn$grade <- as.factor(lcdfrps_trn$grade)
lcdfrps_trn$home_ownership <- as.factor(lcdfrps_trn$home_ownership)
lcdfrps_trn$verification_status <- as.factor(lcdfrps_trn$verification_status)
lcdfrps_trn$purpose <- as.factor(lcdfrps_trn$purpose)
lcdfrps_trn$initial_list_status <- as.factor(lcdfrps_trn$initial_list_status)

# Train the GBM model
GBM_LC <- gbm(
  ret_value ~ ., 
  data = lcdfrps_trn, 
  distribution = "gaussian", 
  n.trees = 1000, 
  shrinkage = 0.01, 
  interaction.depth = 4, 
  bag.fraction = 0.5, 
  cv.folds = 5
)

# Find the best number of trees based on cross-validation
best_iter <- gbm.perf(GBM_LC, method = "cv")

# Predictions on training and test sets for GBM
gbmPredRet_trn <- predict(GBM_LC, newdata = lcdfrps_trn, n.trees = best_iter)
gbmPredRet_tst <- predict(GBM_LC, newdata = lcdfrps_tst, n.trees = best_iter)

# Calculate RMSE for GBM
gbm_rmse_trn <- sqrt(mean((gbmPredRet_trn - lcdfrps_trn$ret_value)^2))
gbm_rmse_tst <- sqrt(mean((gbmPredRet_tst - lcdfrps_tst$ret_value)^2))

# Plot predicted vs actual returns for GBM
plot(gbmPredRet_trn, lcdfrps_trn$ret_value, main = "GBM Predicted vs Actual Returns (Train)")
plot(gbmPredRet_tst, lcdfrps_tst$ret_value, main = "GBM Predicted vs Actual Returns (Test)")

# Step 4: Model Performance Comparison Table
results <- data.frame(
  Model = c("GLM", "Random Forest", "GBM"),
  Train_RMSE = c(glm_rmse_trn, rf_rmse_trn, gbm_rmse_trn),
  Test_RMSE = c(glm_rmse_tst, rf_rmse_tst, gbm_rmse_tst)
)

print(results)





#8. Final Answer: 
#	On Random Forest model, we experimented with number of trees.
#	On GBM, we performed a grid search on minimum observations at each node, bag fraction values, number of trees to find which combination gave minimum root mean square values.
#	On GLM, we performed ridge and lasso regression with multiple lambda values to get minimum RMSE.
#	Actual return being a regression variable. Model performance is done basis RMSE, ie root of minimum square error.
#	It takes the difference of squares between actual values and predicted values.
#	The model that shows lowest RMSE is the best performing. Values are shown in the table below. 
#	In our case, GBM on existing data itself provides lowest RMSE on testing data.





```






```{r}
#9
# Load required libraries
library(dplyr)
library(glmnet)
library(caret)

# Assuming `lcdf` is the complete dataset with `loan_status` and `ret_value`

# Define return value as (total payments - funded amount) / funded amount
lcdf$ret_value <- (lcdf$total_pymnt - lcdf$funded_amnt) / lcdf$funded_amnt

# Set seed for reproducibility
set.seed(123)

# Split the data into 70% training and 30% test sets, retaining `loan_status`
train_index <- createDataPartition(lcdf_filtered$loan_status, p = 0.7, list = FALSE)
lcdfrpse_trn <- lcdf[train_index, ]
lcdfrpse_tst <- lcdf[-train_index, ]

# Check if `loan_status` is available and is a factor in `lcdfrps_trn`
if (!"loan_status" %in% colnames(lcdfrpse_trn) || any(is.na(lcdfrpse_trn$loan_status))) {
  stop("`loan_status` is missing or contains NA values in the training set.")
}

# Ensure `loan_status` is a factor with correct levels
lcdfrpse_trn$loan_status <- factor(lcdfrpse_trn$loan_status, levels = c("1", "2"))
lcdfrpse_tst$loan_status <- factor(lcdfrpse_tst$loan_status, levels = c("1", "2"))

# Step 1: Train GLM for Loan Status Prediction
xTrn_glm1 <- lcdfrpse_trn %>% select(-loan_status, -ret_value, -annRet)
glm1 <- cv.glmnet(data.matrix(xTrn_glm1), as.factor(lcdfrpse_trn$loan_status), family = "binomial")
glm1_pred_Trn <- predict(glm1, data.matrix(xTrn_glm1), type = "response")

# Rank loans by GLM loan status scores
scoreTst_xgb_ls <- lcdfrpse_trn %>% 
  select(grade, loan_status, ret_value, int_rate) %>% 
  mutate(score = glm1_pred_Trn)

# Divide scores into deciles
scoreTst_xgb_ls <- scoreTst_xgb_ls %>% mutate(tile = ntile(-score, 10))

# Summary by decile for loan status model
loan_status_summary <- scoreTst_xgb_ls %>% 
  group_by(tile) %>% 
  summarise(
    count = n(), 
    avgSc = mean(score), 
    numDefaults = sum(loan_status == "Charged Off"),
    avgActRet = mean(ret_value), 
    minRet = min(ret_value), 
    maxRet = max(ret_value),  
    totA = sum(grade == "A"), 
    totB = sum(grade == "B"),
    totC = sum(grade == "C"), 
    totD = sum(grade == "D"), 
    totE = sum(grade == "E"), 
    totF = sum(grade == "F")
  )

print(loan_status_summary)

# Step 2: Train GLM for Return Prediction
xD_ret <- lcdfrpse_trn %>% select(-loan_status, -annRet, -ret_value)
glmRet_cv <- cv.glmnet(data.matrix(xD_ret), lcdfrpse_trn$ret_value, family = "gaussian")
predRet_Trn <- predict(glmRet_cv, data.matrix(xD_ret), s = "lambda.min")

# Rank loans by expected return scores
predRet_Trn <- lcdfrpse_trn %>% 
  select(grade, loan_status, ret_value, int_rate) %>% 
  mutate(predRet = predRet_Trn)

# Divide expected returns into deciles
predRet_Trn <- predRet_Trn %>% mutate(tile = ntile(-predRet, 10))

# Summary by decile for return model
return_summary <- predRet_Trn %>% 
  group_by(tile) %>% 
  summarise(
    count = n(), 
    avgpredRet = mean(predRet), 
    numDefaults = sum(loan_status == "Charged Off"),
    avgActRet = mean(ret_value), 
    minRet = min(ret_value), 
    maxRet = max(ret_value), 
    totA = sum(grade == "A"), 
    totB = sum(grade == "B"),
    totC = sum(grade == "C"), 
    totD = sum(grade == "D"), 
    totE = sum(grade == "E"), 
    totF = sum(grade == "F")
  )

print(return_summary)

# Step 3: Combine Scores for Risk-Return Balancing

# Combine loan status score and return prediction score into a single dataframe
pRetSc <- predRet_Trn %>% mutate(poScore = scoreTst_xgb_ls$score)

# Define a weighting factor between loan status and return score, e.g., 0.5 for equal weighting
weight_risk <- 0.5
weight_return <- 1 - weight_risk

# Calculate combined score
pRetSc <- pRetSc %>% mutate(combinedScore = weight_risk * poScore + weight_return * predRet)

# Step 4: Select top loans based on combined score

# Filter top deciles based on combined score
d <- 1  # Select top decile, can adjust d as needed
pRet_d <- pRetSc %>% filter(tile <= d)

# Ensure data is available for finer tiles calculation
if (nrow(pRet_d) > 0) {
  # Further divide into finer tiles if needed, here into 20 tiles for top decile
  pRet_d <- pRet_d %>% mutate(tile2 = ntile(-combinedScore, 20))
  
  # Summary by finer tiles within top decile
  combined_summary <- pRet_d %>% 
    group_by(tile2) %>% 
    summarise(
      count = n(), 
      avgPredRet = mean(predRet),
      numDefaults = sum(loan_status == "Charged Off"), 
      avgActRet = mean(ret_value), 
      avgTer = mean(int_rate), 
      totA = sum(grade == "A"), 
      totB = sum(grade == "B"),
      totC = sum(grade == "C"), 
      totD = sum(grade == "D"), 
      totE = sum(grade == "E"), 
      totF = sum(grade == "F")
    )
} else {
  stop("No data available in the top decile for combined scoring.")
}

print(combined_summary)

# Step 5: Compare Performance of Combined Model vs Single Models

# Summarize overall performance comparison
model_performance <- data.frame(
  Model = c("Loan Status (GLM)", "Expected Return (GLM)", "Combined Risk-Return"),
  AvgPredReturn = c(mean(loan_status_summary$avgActRet), mean(return_summary$avgActRet), mean(combined_summary$avgActRet)),
  AvgNumDefaults = c(mean(loan_status_summary$numDefaults), mean(return_summary$numDefaults), mean(combined_summary$numDefaults))
)

print(model_performance)


```








```{r}

#10
# Load necessary libraries
library(dplyr)
library(caret)
library(ranger)
library(glmnet)

# Assuming `lcdf` is the full dataset with `loan_status`, `ret_value`, and other columns
# Define return value as (total payments - funded amount) / funded amount
lcdf$ret_value <- (lcdf$total_pymnt - lcdf$funded_amnt) / lcdf$funded_amnt

# Set seed for reproducibility
set.seed(123)

# Step 1: Split the data into training and test sets
train_index <- createDataPartition(lcdf$loan_status, p = 0.7, list = FALSE)
lcdfrps_trn <- lcdf[train_index, ]
lcdfrps_tst <- lcdf[-train_index, ]

# Step 2: Filter the test set to only include lower-grade loans (C, D, E, F)
LC_lowG_Tst <- lcdfrps_tst %>% filter(grade %in% c('C', 'D', 'E', 'F'))

# Step 3: Train Random Forest Model on Lower-Grade Loans
rf_LC_lg <- ranger(
  loan_status ~ ., 
  data = subset(LC_lowG_Tst, select = -c(annRet, ret_value)), 
  num.trees = 200, 
  probability = TRUE, 
  importance = 'permutation'
)

# Score lower-grade loans with Random Forest model predictions
lg_scoreTstRF <- LC_lowG_Tst %>%
  select(grade, loan_status, ret_value, int_rate) %>%
  mutate(score = (predict(rf_LC_lg, LC_lowG_Tst))$predictions[,2]) %>%
  mutate(tile = ntile(-score, 10))

# Summarize performance by decile for Random Forest
rf_summary <- lg_scoreTstRF %>% 
  group_by(tile) %>% 
  summarise(
    count = n(), 
    avgSc = mean(score),
    numDefaults = sum(loan_status == "Charged Off"), 
    avgActRet = mean(ret_value), 
    minRet = min(ret_value), 
    maxRet = max(ret_value),  
    totA = sum(grade == "A"), 
    totB = sum(grade == "B"), 
    totC = sum(grade == "C"), 
    totD = sum(grade == "D"), 
    totE = sum(grade == "E"), 
    totF = sum(grade == "F")
  )

print("Random Forest Model Summary (Lower Grades C-F)")
print(rf_summary)

# Step 4: Prepare data for GLM Model
xD_ret_lc <- LC_lowG_Tst %>% select(-loan_status, -annRet, -ret_value)

# Train GLM model with cross-validation
glmRet_cv <- cv.glmnet(
  data.matrix(xD_ret_lc), 
  LC_lowG_Tst$ret_value, 
  family = "gaussian"
)

# Score lower-grade loans with GLM model predictions
predRet_Trn <- LC_lowG_Tst %>% 
  select(grade, loan_status, ret_value, int_rate) %>%
  mutate(predRet = predict(glmRet_cv, data.matrix(LC_lowG_Tst %>% select(-loan_status, -annRet, -ret_value)), s = "lambda.min")) %>%
  mutate(tile = ntile(-predRet, 10))

# Summarize performance by decile for GLM
glm_summary <- predRet_Trn %>%
  group_by(tile) %>%
  summarise(
    count = n(), 
    avgpredRet = mean(predRet), 
    numDefaults = sum(loan_status == "Charged Off"),
    avgActRet = mean(ret_value), 
    minRet = min(ret_value), 
    maxRet = max(predRet), 
    totA = sum(grade == "A"), 
    totB = sum(grade == "B"), 
    totC = sum(grade == "C"), 
    totD = sum(grade == "D"), 
    totE = sum(grade == "E"), 
    totF = sum(grade == "F")
  )

print("GLM Model Summary (Lower Grades C-F)")
print(glm_summary)




```